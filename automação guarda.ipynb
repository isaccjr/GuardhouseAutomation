{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: DlsEOVERs, Confiança: 0.2485222514511449\n",
      "Texto: sL, Confiança: 0.13545443916121866\n",
      "Texto: ProgFoD, Confiança: 0.2931641876061566\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "from PIL import Image\n",
    "\n",
    "# Crie um leitor (reader)\n",
    "reader = easyocr.Reader(['pt'])  # Especifica o idioma\n",
    "\n",
    "# Ler o texto da imagem\n",
    "results = reader.readtext('6.jpg')\n",
    "\n",
    "# Imprimir os resultados\n",
    "for (bbox, text, prob) in results:\n",
    "    print(f'Texto: {text}, Confiança: {prob}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: @YF5J92, Confiança: 0.8342566675176543\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "# Carregar a imagem em escala de cinza\n",
    "image = cv2.imread('5.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "image_contraste = cv2.equalizeHist(image)\n",
    "\n",
    "# Aplicar Unsharp Masking\n",
    "gaussian_blur = cv2.GaussianBlur(image_contraste, (9, 9), 10.0)\n",
    "sharpened = cv2.addWeighted(image_contraste, 1.5, gaussian_blur, -0.5, 0)\n",
    "\n",
    "# Salvar a imagem ajustada\n",
    "cv2.imwrite('imagem_nitida.jpg', sharpened)\n",
    "\n",
    "# Ler a imagem ajustada\n",
    "reader = easyocr.Reader(['pt'])\n",
    "results = reader.readtext(sharpened, text_threshold=0.7, low_text=0.4, link_threshold=0.4)\n",
    "\n",
    "# Imprimir os resultados\n",
    "for (bbox, text, prob) in results:\n",
    "    print(f'Texto: {text}, Confiança: {prob}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placa\n",
      "Texto: lesl, Confiança: 0.0570419542491436\n",
      "Texto: Pro8Foo, Confiança: 0.4702001546750024\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os nomes das classes\n",
    "with open(\"classes.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Carregar o modelo YOLO pré-treinado e as classes\n",
    "net = cv2.dnn.readNet(\"custom-yolov4-detector_final.weights\", \"custom-yolov4-detector.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Carregar a imagem\n",
    "image = cv2.imread('6.jpg')\n",
    "height, width, channels = image.shape\n",
    "\n",
    "# Preparar a imagem para YOLO\n",
    "blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "# Processar as detecções\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:  # Ajuste o limiar de confiança conforme necessário\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "# Aplicar Non-Max Suppression\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "# Cortar a região da placa\n",
    "for i in range(len(boxes)):\n",
    "    if i in indices:\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        print(label)\n",
    "        if label == \"placa\":  # Certifique-se de que a classe está correta\n",
    "            roi = image[y:y+h, x:x+w]\n",
    "            # Salvar a região da placa\n",
    "            cv2.imwrite('placa.jpg', roi)\n",
    "\n",
    "# Ler a região da placa usando EasyOCR\n",
    "reader = easyocr.Reader(['pt'])\n",
    "results = reader.readtext('placa.jpg')\n",
    "\n",
    "# Imprimir os resultados\n",
    "for (bbox, text, prob) in results:\n",
    "    print(f'Texto: {text}, Confiança: {prob}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Obter o caminho absoluto do arquivo de credenciais na pasta atual do projeto\n",
    "current_directory = os.getcwd()\n",
    "credential_path = os.path.join(current_directory, \"application_default_credentials.json\")\n",
    "\n",
    "# Definir a variável de ambiente GOOGLE_APPLICATION_CREDENTIALS\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credential_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto detectado: ◄ Busca.\n",
      "21:36\n",
      "HABILITAÇÃO\n",
      "Atualizado em: 10/12/2024 - 21:30:10\n",
      "Verifique autenticidade do QR Code com o app Vio\n",
      "VÁLIDA EM TODO\n",
      "O TERRITÓRIO NACIONAL\n",
      "2259590237\n",
      "REPÚBLICA FEDERATIVA DO BRASIL\n",
      "MINISTÉRIO DA INFRAESTRUTURA\n",
      "DEPARTAMENTO NACIONAL DE TRÂNSITO\n",
      "CARTEIRA NACIONAL DE HABILITAÇÃO\n",
      "NOME\n",
      "ISAC SOARES CAMARA JUNIOR\n",
      "DOC. IDENTIDADE/ORG EMISSOR/UF\n",
      "2617795 SSP DF\n",
      "CPF\n",
      "016.016.291-25\n",
      "-FILIAÇÃO\n",
      "ISAC SOARES CAMARA\n",
      "DATA NASCIMENTO-\n",
      "19/09/1987\n",
      "N° REGISTRO\n",
      "03931237097\n",
      "VALIDADE\n",
      "22/06/2031\n",
      "B\n",
      "CAT. HAB.-\n",
      "1 HABILITAÇÃO\n",
      "16/09/2006\n",
      "MIRIAN ANDRELINO SOARES CAM\n",
      "ARA\n",
      "PERMISSÃO\n",
      "ACC\n",
      "D\n",
      "OF\n",
      "Histórico de emissões da CNH\n",
      "Placas encontradas: Nenhuma placa encontrada no texto detectado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import vision\n",
    "import re\n",
    "\n",
    "\n",
    "# Configura o cliente da API\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "def extract_license_plate(image_path):\n",
    "    try:\n",
    "        with open(image_path, 'rb') as image_file:\n",
    "            content = image_file.read()\n",
    "\n",
    "        image = vision.Image(content=content)\n",
    "        response = client.text_detection(image=image)\n",
    "        texts = response.text_annotations\n",
    "\n",
    "        if not texts:\n",
    "            return \"Nenhum texto detectado na imagem.\"\n",
    "\n",
    "        full_text = texts[0].description\n",
    "        print(f\"Texto detectado: {full_text}\")\n",
    "\n",
    "        plate_pattern = r'[A-Z]{3}[0-9][A-Z0-9][0-9]{2}'\n",
    "        matches = re.findall(plate_pattern, full_text)\n",
    "\n",
    "        if matches:\n",
    "            return matches\n",
    "        else:\n",
    "            return \"Nenhuma placa encontrada no texto detectado.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar a imagem: {e}\")\n",
    "        return None\n",
    "\n",
    "# Exemplo de uso\n",
    "image_path = \"8.PNG\"  # Substitua pelo caminho da sua imagem\n",
    "plates = extract_license_plate(image_path)\n",
    "print(f\"Placas encontradas: {plates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Placa    | Modelo     | Marca    | Cor      | Nome                    | CPF              | RG                |\n",
      "| :------- | :--------- | :------- | :------- | :---------------------- | :--------------- | :---------------- |\n",
      "| QYF5J92 | Onix       | Chevrolet | Branco   | Isac Soares Camara Junior | 016.016.291-25 | 2677795 SSP DF   |\n",
      "| PRQ8F00 | Discovery Sport | Land Rover | Azul Escuro | Rafaela Kuhn Valandro    | 016.718.370-29 | 1077638623 SJS/RS |\n",
      "| IMPERIAL | Mobi       | Fiat     | Branco   | Gilveano Cota          | 020.856.860-36 | 1092477941 SSP RS |"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, SafetySetting\n",
    "\n",
    "\n",
    "def generate():\n",
    "    vertexai.init(project=\"guardautomation\", location=\"us-central1\")\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-pro-002\",\n",
    "    )\n",
    "    responses = model.generate_content(\n",
    "        [image1, image2, image3, image4, image5, image6, text1],\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    for response in responses:\n",
    "        print(response.text, end=\"\")\n",
    "\n",
    "text1 = \"\"\"Crie uma tabela com a placa, modelo e marca do carro, cor,  nome, cpf. Nome, sobrenome , cpf e rg estão nas imagens posteriores a dos carros, a imagem 1 com a 2 e a 3 com a 4 e assim posteriormente. Responda somente a tabela nada além da tabela.\"\"\"\n",
    "\n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "]\n",
    "\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagens\\documentos\\1.jpg\n",
      "imagens\\documentos\\2.jpg\n",
      "imagens\\documentos\\3.jpg\n"
     ]
    }
   ],
   "source": [
    "#listando arquivos do diretorio\n",
    "from pathlib import Path\n",
    "\n",
    "diretorio = Path(\"imagens/documentos\")\n",
    "\n",
    "# Listar todos os arquivos\n",
    "for arquivo in diretorio.iterdir():\n",
    "    if arquivo.is_file():\n",
    "        print(arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024:12:09 22:01:55\n"
     ]
    }
   ],
   "source": [
    "#extraindo metadados\n",
    "import exifread\n",
    "\n",
    "def get_image_datetime(image_path):\n",
    "    with open(image_path, 'rb') as f:\n",
    "        tags = exifread.process_file(f)\n",
    "\n",
    "        # A data e hora geralmente estão em tags como 'DateTimeOriginal' ou 'DateTimeDigitized'\n",
    "        datetime_original = tags.get('EXIF DateTimeOriginal')\n",
    "        datetime_digitized = tags.get('EXIF DateTimeDigitized')\n",
    "\n",
    "        if datetime_original:\n",
    "            return datetime_original.values\n",
    "        elif datetime_digitized:\n",
    "            return datetime_digitized.values\n",
    "        else:\n",
    "            return \"Data não encontrada nos metadados EXIF\"\n",
    "\n",
    "# Substitua 'caminho/para/sua/imagem.jpg' pelo caminho da sua imagem\n",
    "image_path = 'imagens/documentos/1.jpg'\n",
    "datetime = get_image_datetime(image_path)\n",
    "print(datetime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "googlevision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
